{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys as sy\n",
    "import struct as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data\n",
    "fpI = open('/home2/bamboo/local_workspace/workspace/Out/barbara512/ewpLH-ImgRes_0.dig', 'rb')\n",
    "nxI = fpI.read(4)\n",
    "nxI = st.unpack(\"i\", nxI)\n",
    "nxI = nxI[0]\n",
    "nyI = fpI.read(4)\n",
    "nyI = st.unpack(\"i\", nyI)\n",
    "nyI = nyI[0]\n",
    "img_target = []\n",
    "for _ in range(nxI * nyI):\n",
    "    data = fpI.read(8)\n",
    "    data = st.unpack(\"d\", data)\n",
    "    data = data[0]\n",
    "    img_target.append(data)\n",
    "fpI.close()\n",
    "img_target = np.array(img_target)\n",
    "target = img_target.reshape(nyI, nxI)\n",
    "fpIL = open('/home2/bamboo/local_workspace/workspace/Out/barbara512/ewpLH-LImgRes_0.dig', 'rb')\n",
    "nxIL = fpIL.read(4)\n",
    "nxIL = st.unpack(\"i\", nxIL)\n",
    "nxIL = nxIL[0]\n",
    "nyIL = fpIL.read(4)\n",
    "nyIL = st.unpack(\"i\", nyIL)\n",
    "nyIL = nyIL[0]\n",
    "img_low = []\n",
    "for _ in range(nxIL * nyIL):\n",
    "    data = fpIL.read(8)\n",
    "    data = st.unpack(\"d\", data)\n",
    "    data = data[0]\n",
    "    img_low.append(data)\n",
    "fpIL.close()\n",
    "img_low = np.array(img_low)\n",
    "low = img_low.reshape(nyIL, nxIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of extract block\n",
    "width = nxI\n",
    "height = nyI\n",
    "wid_block = 10\n",
    "hei_block = 10\n",
    "num_target = 2\n",
    "num_blocks = (width - (wid_block - num_target)) * (height - (hei_block - 1))\n",
    "init_target = 2 * height + 2\n",
    "half_widblock = int(wid_block * 0.5)\n",
    "dim_block = int(wid_block * hei_block)\n",
    "wid_target_block = wid_block\n",
    "hei_target_block = hei_block - 1\n",
    "dim_target_block = wid_target_block * hei_target_block\n",
    "wid_low_block = wid_block\n",
    "hei_low_block = 1\n",
    "dim_low_block = wid_low_block * hei_low_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset\n",
    "arr_data = []\n",
    "for y in range(height - hei_block + 1):\n",
    "    for x in range(0, width - wid_block + 1, 2):\n",
    "        target_block = target[y:y+hei_target_block, x:x+wid_target_block]\n",
    "        target_block = target_block.reshape(dim_target_block, 1)\n",
    "        arr_data.extend(target_block)\n",
    "        low_block = low[y + 2, x:x+wid_low_block]\n",
    "        low_block = low_block.reshape(dim_low_block, 1)\n",
    "        arr_data.extend(low_block)\n",
    "train_data = np.array(arr_data)\n",
    "train_x = train_data.reshape(int(train_data.size / dim_block), dim_block)\n",
    "d = []\n",
    "for y in range(hei_block - 1, height, 1):\n",
    "    for x in range(half_widblock - 1, width - (half_widblock - 1), 2):\n",
    "        label = target[y, x:x+2]\n",
    "        d.append(label)\n",
    "label = np.array(d)\n",
    "train_label = np.reshape(label, (len(train_x), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62244, 100)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define num\n",
    "num_input_units = dim_block\n",
    "num_hidden_units = 68\n",
    "# num_hidden2_units = \n",
    "# num_hidden3_units = 28\n",
    "# num_hidden4_units = 28\n",
    "# num_hidden5_units = 28\n",
    "learning_rate = 0.0001\n",
    "num_iter = 5000\n",
    "num_output = 2\n",
    "train_size = train_x.shape[0]\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters, output is 2\n",
    "x = tf.placeholder(tf.float32, [None, num_input_units])\n",
    "wscale = 2.0\n",
    "sigma1 = tf.sqrt(1.0/num_input_units * wscale)\n",
    "sigma2 = tf.sqrt(1.0/num_hidden_units * wscale)\n",
    "# sigma3 = tf.sqrt(1.0/num_hidden2_units * wscale)\n",
    "# sigma4 = tf.sqrt(1.0/num_hidden3_units * wscale)\n",
    "# sigma5 = tf.sqrt(1.0/num_hidden4_units * wscale)\n",
    "# sigma6 = tf.sqrt(1.0/num_hidden5_units * wscale)\n",
    "\n",
    "#hidden layer 1\n",
    "w_h_1 = tf.Variable(tf.random_normal(shape=[num_input_units, num_hidden_units], stddev=sigma1))\n",
    "b_h_1 = tf.Variable(tf.zeros([num_hidden_units]))\n",
    "\n",
    "#hidden layer2\n",
    "w_h_2 = tf.Variable(tf.random_normal(shape=[num_hidden_units, num_hidden_units], stddev=sigma2))\n",
    "b_h_2 = tf.Variable(tf.zeros([num_hidden_units]))\n",
    "\n",
    "# #hidden layer3\n",
    "# w_h_3 = tf.Variable(tf.random_normal(shape=[num_hidden2_units, num_hidden3_units], stddev=sigma3))\n",
    "# b_h_3 = tf.Variable(tf.zeros([num_hidden3_units]))\n",
    "\n",
    "# #hidden layer4\n",
    "# w_h_4 = tf.Variable(tf.random_normal(shape=[num_hidden3_units, num_hidden4_units], stddev=sigma4))\n",
    "# b_h_4 = tf.Variable(tf.zeros([num_hidden4_units]))\n",
    "\n",
    "# #hidden layer5\n",
    "# w_h_5 = tf.Variable(tf.random_normal(shape=[num_hidden4_units, num_hidden5_units], stddev=sigma5))\n",
    "# b_h_5 = tf.Variable(tf.zeros([num_hidden5_units]))\n",
    "\n",
    "#output layer\n",
    "w_o = tf.Variable(tf.random_normal(shape=[num_hidden_units, num_output], stddev=sigma2))\n",
    "b_o = tf.Variable(tf.zeros([num_output]))\n",
    "\n",
    "#calculate hidden layer\n",
    "h_1 = tf.nn.relu(tf.matmul(x, w_h_1) + b_h_1)\n",
    "h_2 = tf.nn.relu(tf.matmul(h_1, w_h_2) + b_h_2)\n",
    "# h_3 = tf.nn.relu(tf.matmul(h_2, w_h_3) + b_h_3)\n",
    "# h_4 = tf.nn.relu(tf.matmul(h_3, w_h_4) + b_h_4)\n",
    "# h_5 = tf.nn.relu(tf.matmul(h_4, w_h_5) + b_h_5)\n",
    "\n",
    "#calculate output layer\n",
    "y = tf.matmul(h_2, w_o) + b_o\n",
    "\n",
    "t = tf.placeholder(tf.float32, [None, num_output])\n",
    "\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y, t)\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "LOSS = sess.run(tf.sqrt(loss), feed_dict={x:train_x, t:train_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 117.174957\n",
      "Step: 100, Loss: 21.775331\n",
      "Step: 200, Loss: 18.078091\n",
      "Step: 300, Loss: 15.266818\n",
      "Step: 400, Loss: 15.266818\n",
      "Step: 500, Loss: 13.902082\n",
      "Step: 600, Loss: 13.902082\n",
      "Step: 700, Loss: 13.902082\n",
      "Step: 800, Loss: 13.902082\n",
      "Step: 900, Loss: 13.902082\n",
      "Step: 1000, Loss: 13.902082\n",
      "Step: 1100, Loss: 13.902082\n",
      "Step: 1200, Loss: 13.902082\n",
      "Step: 1300, Loss: 13.902082\n",
      "Step: 1400, Loss: 13.698524\n",
      "Step: 1500, Loss: 13.100378\n",
      "Step: 1600, Loss: 13.100378\n",
      "Step: 1700, Loss: 13.100378\n",
      "Step: 1800, Loss: 13.100378\n",
      "Step: 1900, Loss: 13.100378\n",
      "Step: 2000, Loss: 12.609237\n",
      "Step: 2100, Loss: 12.609237\n",
      "Step: 2200, Loss: 12.609237\n",
      "Step: 2300, Loss: 12.609237\n",
      "Step: 2400, Loss: 12.609237\n",
      "Step: 2500, Loss: 12.609237\n",
      "Step: 2600, Loss: 12.609237\n",
      "Step: 2700, Loss: 10.935732\n",
      "Step: 2800, Loss: 10.935732\n",
      "Step: 2900, Loss: 10.935732\n",
      "Step: 3000, Loss: 10.935732\n",
      "Step: 3100, Loss: 10.935732\n",
      "Step: 3200, Loss: 10.935732\n",
      "Step: 3300, Loss: 10.935732\n",
      "Step: 3400, Loss: 10.935732\n",
      "Step: 3500, Loss: 10.935732\n",
      "Step: 3600, Loss: 10.935732\n",
      "Step: 3700, Loss: 10.935732\n",
      "Step: 3800, Loss: 10.935732\n",
      "Step: 3900, Loss: 10.935732\n",
      "Step: 4000, Loss: 10.935732\n",
      "Step: 4100, Loss: 10.935732\n",
      "Step: 4200, Loss: 10.853783\n",
      "Step: 4300, Loss: 10.853783\n",
      "Step: 4400, Loss: 10.853783\n",
      "Step: 4500, Loss: 10.853783\n",
      "Step: 4600, Loss: 10.853783\n",
      "Step: 4700, Loss: 10.853783\n",
      "Step: 4800, Loss: 10.853783\n",
      "Step: 4900, Loss: 10.853783\n",
      "Step: 5000, Loss: 10.853783\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "# start iterating\n",
    "for i in range(num_iter + 1):\n",
    "#     batch_xs, batch_ts = train_data.train.next_batch(100)\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    batch_x = train_x[batch_mask]\n",
    "    batch_label = train_label[batch_mask]\n",
    "    sess.run(train_step, feed_dict={x:batch_x, t:batch_label})\n",
    "    loss_new = sess.run(tf.sqrt(loss), feed_dict={x:batch_x, t:batch_label})\n",
    "    if LOSS > loss_new:\n",
    "        LOSS = loss_new\n",
    "        weight_1 = sess.run(w_h_1)\n",
    "        weight_2 = sess.run(w_h_2)\n",
    "#         weight_3 = sess.run(w_h_3)\n",
    "#         weight_4 = sess.run(w_h_4)\n",
    "#         weight_5 = sess.run(w_h_5)\n",
    "        weight_out = sess.run(w_o)\n",
    "        bias_1 = sess.run(b_h_1)\n",
    "        bias_2 = sess.run(b_h_2)\n",
    "#         bias_3 = sess.run(b_h_3)\n",
    "#         bias_4 = sess.run(b_h_4)\n",
    "#         bias_5 = sess.run(b_h_5)\n",
    "        bias_out = sess.run(b_o)\n",
    "    if(i % 100 == 0):\n",
    "        print('Step: %d, Loss: %f' % (i, LOSS))\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the error value for test image\n",
    "# Read image data\n",
    "fpI_test = open('/home2/bamboo/local_workspace/workspace/Out/n1/ewpLH-ImgRes_0.dig', 'rb')\n",
    "nxI_test = fpI_test.read(4)\n",
    "nxI_test = st.unpack(\"i\", nxI_test)\n",
    "nxI_test = nxI_test[0]\n",
    "nyI_test = fpI_test.read(4)\n",
    "nyI_test = st.unpack(\"i\", nyI_test)\n",
    "nyI_test = nyI_test[0]\n",
    "img_target_test = []\n",
    "for _ in range(nxI_test * nyI_test):\n",
    "    data = fpI_test.read(8)\n",
    "    data = st.unpack(\"d\", data)\n",
    "    data = data[0]\n",
    "    img_target_test.append(data)\n",
    "fpI_test.close()\n",
    "img_target_test = np.array(img_target_test)\n",
    "target_test = img_target_test.reshape(nyI_test, nxI_test)\n",
    "fpIL_test = open('/home2/bamboo/local_workspace/workspace/Out/n1/ewpLH-LImgRes_0.dig', 'rb')\n",
    "nxIL_test = fpIL_test.read(4)\n",
    "nxIL_test = st.unpack(\"i\", nxIL_test)\n",
    "nxIL_test = nxIL_test[0]\n",
    "nyIL_test = fpIL_test.read(4)\n",
    "nyIL_test = st.unpack(\"i\", nyIL_test)\n",
    "nyIL_test = nyIL_test[0]\n",
    "img_low_test = []\n",
    "for _ in range(nxIL_test * nyIL_test):\n",
    "    data = fpIL_test.read(8)\n",
    "    data = st.unpack(\"d\", data)\n",
    "    data = data[0]\n",
    "    img_low_test.append(data)\n",
    "fpIL_test.close()\n",
    "img_low_test = np.array(img_low_test)\n",
    "low_test = img_low_test.reshape(nyIL_test, nxIL_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset\n",
    "height_test = nyI_test\n",
    "width_test = nxI_test\n",
    "num_blocks_test = (width_test - (wid_block - num_target)) * (height_test - (hei_block - 1))\n",
    "init_target_test = 2 * height_test + 2\n",
    "test_arr = []\n",
    "for y in range(height_test - hei_block + 1):\n",
    "    for x in range(0, width_test - wid_block + 1, 2):\n",
    "        target_block_test = target_test[y:y+hei_target_block, x:x+wid_target_block]\n",
    "        target_block_test = target_block_test.reshape(dim_target_block, 1)\n",
    "        test_arr.extend(target_block_test)\n",
    "        low_block_test = low_test[y + 2, x:x+wid_low_block]\n",
    "        low_block_test = low_block_test.reshape(dim_low_block, 1)\n",
    "        test_arr.extend(low_block_test)\n",
    "test_data = np.array(test_arr)\n",
    "test_x = test_data.reshape(int(test_data.size / dim_block), dim_block)\n",
    "\n",
    "d = []\n",
    "for y in range(hei_block - 1, height_test, 1):\n",
    "    for x in range(half_widblock - 1, width_test - (half_widblock - 1), 2):\n",
    "        label = target_test[y, x:x+2]\n",
    "        d.append(label)\n",
    "label = np.array(d)\n",
    "test_label = np.reshape(label, (len(test_x), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "neuralReLU = np.frompyfunc(relu, 1, 1)\n",
    "\n",
    "# Calculate 1st hidden layer\n",
    "hidden_1 = neuralReLU(np.dot(test_x, weight_1) + bias_1)\n",
    "\n",
    "# Caluclate 2nd hidden layer\n",
    "hidden_2 = neuralReLU(np.dot(hidden_1, weight_2) + bias_2)\n",
    "\n",
    "# Calculate output layer\n",
    "out = neuralReLU(np.dot(hidden_2, weight_out) + bias_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6178759421296935\n",
      "2.4014211948697026\n",
      "17.722539228506097\n",
      "17.504700958254755\n"
     ]
    }
   ],
   "source": [
    "# Calculate error value\n",
    "def sumOfAbsLog(arr):\n",
    "    sum = 0\n",
    "    for i in arr:\n",
    "        sum += np.log2(np.abs(i) + 1)\n",
    "    return sum\n",
    "    \n",
    "def sumOfSquErr(arr):\n",
    "    sum = 0\n",
    "    for i in arr:\n",
    "        sum += np.power(i, 2)\n",
    "    return sum\n",
    "\n",
    "# Sum of absolute log value\n",
    "error_arr = out - test_label\n",
    "N = error_arr[:,0].size\n",
    "\n",
    "\n",
    "error_log_odd = sumOfAbsLog(error_arr[:,0]) / N\n",
    "error_log_even = sumOfAbsLog(error_arr[:,1]) / N\n",
    "\n",
    "# Root of Mean Squared Error\n",
    "error_rmse_odd = np.sqrt(sumOfSquErr(error_arr[:,0]) / N)\n",
    "error_rmse_even = np.sqrt(sumOfSquErr(error_arr[:,1]) / N)\n",
    "\n",
    "print(error_log_odd)\n",
    "print(error_log_even)\n",
    "print(error_rmse_odd)\n",
    "print(error_rmse_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.160284682123663\n",
      "23.267709690878753\n"
     ]
    }
   ],
   "source": [
    "PSNR_odd = 20*np.log10(255/error_rmse_odd)\n",
    "PSNR_even = 20*np.log10(255/error_rmse_even)\n",
    "print(PSNR_odd)\n",
    "print(PSNR_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1021917040646363\n",
      "1.6405694399701571\n",
      "3.6927903201852086\n",
      "8.243116113957182\n"
     ]
    }
   ],
   "source": [
    "# Calculate error value w/o prediction\n",
    "LImgRes = []\n",
    "for y in range(hei_block - 1, height_test, 1):\n",
    "    for x in range(half_widblock - 1, width_test - (half_widblock - 1), 2):\n",
    "        label = low_test[y, x:x+2]\n",
    "        LImgRes.append(label)\n",
    "label = np.array(LImgRes)\n",
    "LImgRes_label = np.reshape(label, (len(test_x), 2))\n",
    "\n",
    "# Sum of absolute log value\n",
    "error_arr_wo_prediction = LImgRes_label - test_label\n",
    "N = error_arr_wo_prediction[:,0].size\n",
    "error_log_odd_wo_prediction = sumOfAbsLog(error_arr_wo_prediction[:,0]) / N\n",
    "error_log_even_wo_prediction = sumOfAbsLog(error_arr_wo_prediction[:,1]) / N\n",
    "\n",
    "# Root of Mean Squared Error\n",
    "error_rmse_odd_wo_prediction = np.sqrt(sumOfSquErr(error_arr_wo_prediction[:,0]) / N)\n",
    "error_rmse_even_wo_prediction = np.sqrt(sumOfSquErr(error_arr_wo_prediction[:,1]) / N)\n",
    "\n",
    "print(error_log_odd_wo_prediction)\n",
    "print(error_log_even_wo_prediction)\n",
    "print(error_rmse_odd_wo_prediction)\n",
    "print(error_rmse_even_wo_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.783710633952474\n",
      "29.8089752600018\n"
     ]
    }
   ],
   "source": [
    "PSNR_odd = 20*np.log10(255/error_rmse_odd_wo_prediction)\n",
    "PSNR_even = 20*np.log10(255/error_rmse_even_wo_prediction)\n",
    "print(PSNR_odd)\n",
    "print(PSNR_even)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
